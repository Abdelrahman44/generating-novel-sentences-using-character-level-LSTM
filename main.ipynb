{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook, I construct novel sentences using LSTM network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chapter 1\\n\\n\\nHappy families are all alike; every un'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/anna.txt') as file:\n",
    "    text = file.read()\n",
    "    \n",
    "text[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one-hot encoding of the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = tuple(set(text))\n",
    "int2char = dict(enumerate(vocab))\n",
    "char2int = {char: i for i, char in int2char.items()}\n",
    "encoded_text = np.array([char2int[char] for char in text])  # [95, 6, 13, 95, ...] corresponding to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15, 14,  3, 30, 12, 18, 65, 38, 76, 57, 57, 57, 22,  3, 30, 30, 37,\n",
       "       38, 58,  3, 44, 13, 41, 13, 18, 24, 38,  3, 65, 18, 38,  3, 41, 41,\n",
       "       38,  3, 41, 13, 64, 18, 16, 38, 18,  0, 18, 65, 37, 38, 32, 66])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one-hot encoding of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(arr, n_labels):    #n_labels is the number of unique words (vocabulary), arr is the text\n",
    "    \n",
    "    one_hot = np.zeros((np.multiply(*arr.shape), n_labels), dtype=np.float32)\n",
    "\n",
    "    one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1.    #this creates the on-hot encoded vector\n",
    "    \n",
    "    one_hot = one_hot.reshape((*arr.shape, n_labels))\n",
    "\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getting batches of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(encoded_text, n_seq, n_steps):\n",
    "    batch_size = n_seq * n_steps\n",
    "    n_batches = len(encoded_text) // batch_size\n",
    "    encoded_text = encoded_text[:n_batches*batch_size]          # drop some data to get only full batches\n",
    "    encoded_text = encoded_text.reshape((n_seq, -1))        \n",
    "    \n",
    "    for i in range(0, encoded_text.shape[1], n_steps):  # iterate on the columns to get the batches\n",
    "        x = encoded_text[:, i:i+n_steps]\n",
    "        y = np.zeros_like(x)\n",
    "        try:\n",
    "            y[:, :-1], y[:, -1] = x[:, 1:], encoded_text[:, i+n_steps]\n",
    "        except IndexError:\n",
    "            y[:, :-1], y[:, -1] = x[:, 1:], encoded_text[:, 0]\n",
    "        yield x, y                              # x, y are generators that you can use next() on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      " [[15 14  3 30 12 18 65 38 76 57]\n",
      " [38  3 44 38 66 46 12 38 21 46]\n",
      " [ 0 13 66 60 57 57 42 25 18 24]\n",
      " [66 38 20 32 65 13 66 21 38 14]\n",
      " [38 13 12 38 13 24 51 38 24 13]\n",
      " [38 29 12 38 59  3 24 57 46 66]\n",
      " [14 18 66 38 68 46 44 18 38 58]\n",
      " [16 38  2 32 12 38 66 46 59 38]\n",
      " [12 38 13 24 66  9 12 60 38  4]\n",
      " [38 24  3 13 20 38 12 46 38 14]]\n",
      "\n",
      "y\n",
      " [[14  3 30 12 18 65 38 76 57 57]\n",
      " [ 3 44 38 66 46 12 38 21 46 13]\n",
      " [13 66 60 57 57 42 25 18 24 51]\n",
      " [38 20 32 65 13 66 21 38 14 13]\n",
      " [13 12 38 13 24 51 38 24 13 65]\n",
      " [29 12 38 59  3 24 57 46 66 41]\n",
      " [18 66 38 68 46 44 18 38 58 46]\n",
      " [38  2 32 12 38 66 46 59 38 24]\n",
      " [38 13 24 66  9 12 60 38  4 14]\n",
      " [24  3 13 20 38 12 46 38 14 18]]\n",
      "(10, 50) (10, 50)\n"
     ]
    }
   ],
   "source": [
    "batches = get_batches(encoded_text, 10, 50)\n",
    "x, y = next(batches)\n",
    "print('x\\n', x[:10, :10])\n",
    "print('\\ny\\n', y[:10, :10])\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## defining the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab, n_steps=100, n_hidden=256, n_layers=4, drop_prop=0.5, lr=0.001):\n",
    "        # n_steps: number of elements in each sequence in each batch\n",
    "        # n_hidden: number of output elements of the intermediate layers\n",
    "        # n_layers: number of LSTM layers to use\n",
    "        \n",
    "        super().__init__()\n",
    "        self.drop_prop = drop_prop\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_steps = n_steps\n",
    "        self.lr = lr\n",
    "        \n",
    "        self.vocab = vocab\n",
    "        self.int2char = dict(enumerate(self.vocab))\n",
    "        self.char2int = {char: i for i, char in self.int2char.items()}\n",
    "        \n",
    "        self.lstm = nn.LSTM(len(self.vocab), n_hidden, n_layers, dropout=drop_prop, batch_first=True)\n",
    "        self.dropout = nn.Dropout(drop_prop)\n",
    "        self.fc = nn.Linear(n_hidden, len(self.vocab))\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x, hc):\n",
    "        x, (h, c) = self.lstm(x, hc)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x.view(x.shape[0]*x.shape[1], self.n_hidden))\n",
    "        \n",
    "        return x, (h, c)\n",
    "    \n",
    "    def predict(self, x, h=None, cuda=False):\n",
    "        if cuda:\n",
    "            self.cuda()\n",
    "        else:\n",
    "            self.cpu()\n",
    "            \n",
    "        x = np.array([[self.char2int[x]]])\n",
    "        x = one_hot_encode(x, len(self.vocab))\n",
    "        x = torch.from_numpy(x)\n",
    "        \n",
    "        if h == None:\n",
    "            h = init_hidden(1)\n",
    "            \n",
    "        h = tuple([each.data for each in h])\n",
    "        \n",
    "        if cuda:\n",
    "            x = x.cuda()\n",
    "            \n",
    "        out, h = self.forward(x, h)\n",
    "        p = F.softmax(out, dim=1).data\n",
    "                \n",
    "        p.cpu()\n",
    "\n",
    "        top_ch = np.arange(len(self.vocab))\n",
    "\n",
    "        p = p.numpy().squeeze()\n",
    "        char = np.random.choice(top_ch, p=p/p.sum())\n",
    "            \n",
    "        return self.int2char[char], h\n",
    "    \n",
    "    \n",
    "    def init_weights(self):\n",
    "        self.fc.bias.data.fill_(0)\n",
    "        self.fc.weight.data.uniform_(-1, 1)\n",
    "        \n",
    "        \n",
    "    def init_hidden(self, n_seqs):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x n_seqs x n_hidden,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        return (weight.new(self.n_layers, n_seqs, self.n_hidden).zero_(),\n",
    "                weight.new(self.n_layers, n_seqs, self.n_hidden).zero_())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CharRNN(\n",
      "  (lstm): LSTM(83, 512, num_layers=4, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.5)\n",
      "  (fc): Linear(in_features=512, out_features=83, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "if 'net' in locals():\n",
    "    del net\n",
    "    \n",
    "net = CharRNN(vocab, n_hidden=512)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, encoded_text, epochs=10, n_seq=10, n_steps=50, lr=0.001, cuda=True, clip=5, print_every=10):\n",
    "    \n",
    "    net.train(True)\n",
    "    opt = torch.optim.Adam(net.parameters(), lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    train_txt, val_txt = encoded_text[:-int(0.2*len(encoded_text))], encoded_text[-int(0.2*len(encoded_text)):]\n",
    "    if cuda:\n",
    "        net.cuda()\n",
    "        \n",
    "    counter = 0\n",
    "    n_chars = len(net.vocab)\n",
    "    for e in range(epochs):\n",
    "        h = net.init_hidden(n_seq)\n",
    "        for x, y in get_batches(encoded_text, n_seq, n_steps):\n",
    "            counter +=1\n",
    "            x = one_hot_encode(x, n_chars)\n",
    "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
    "            if cuda:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "                \n",
    "            h = tuple([each.data for each in h])\n",
    "            \n",
    "            net.zero_grad()\n",
    "            output, h = net(inputs, h)\n",
    "            loss = criterion(output, targets.view(n_seq*n_steps))\n",
    "            loss.backward()\n",
    "            \n",
    "                   # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "\n",
    "            opt.step()\n",
    "            \n",
    "            if counter % print_every == 0:\n",
    "                \n",
    "                # Get validation loss\n",
    "                val_h = net.init_hidden(n_seq)\n",
    "                val_losses = []\n",
    "                for x, y in get_batches(val_txt, n_seq, n_steps):\n",
    "                    # One-hot encode our data and make them Torch tensors\n",
    "                    x = one_hot_encode(x, n_chars)\n",
    "                    x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
    "                    \n",
    "                    # Creating new variables for the hidden state, otherwise\n",
    "                    # we'd backprop through the entire training history\n",
    "                    val_h = tuple([each.data for each in val_h])\n",
    "                    \n",
    "                    inputs, targets = x, y\n",
    "                    if cuda:\n",
    "                        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "                    output, val_h = net.forward(inputs, val_h)\n",
    "                    val_loss = criterion(output, targets.view(n_seq*n_steps))\n",
    "                \n",
    "                    val_losses.append(val_loss.item())\n",
    "                \n",
    "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                      \"Step: {}...\".format(counter),\n",
    "                      \"Loss: {:.4f}...\".format(loss.item()),\n",
    "                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Step: 10... Loss: 3.3637... Val Loss: 3.4008\n",
      "Epoch: 1/1... Step: 20... Loss: 3.2801... Val Loss: 3.2904\n",
      "Epoch: 1/1... Step: 30... Loss: 3.2566... Val Loss: 3.2713\n",
      "Epoch: 1/1... Step: 40... Loss: 3.2389... Val Loss: 3.2534\n",
      "Epoch: 1/1... Step: 50... Loss: 3.2142... Val Loss: 3.2329\n",
      "Epoch: 1/1... Step: 60... Loss: 3.1688... Val Loss: 3.1867\n",
      "Epoch: 1/1... Step: 70... Loss: 3.0616... Val Loss: 3.0624\n",
      "Epoch: 1/1... Step: 80... Loss: 2.9807... Val Loss: 2.9854\n",
      "Epoch: 1/1... Step: 90... Loss: 2.9399... Val Loss: 2.9256\n",
      "Epoch: 1/1... Step: 100... Loss: 2.8552... Val Loss: 2.8692\n",
      "Epoch: 1/1... Step: 110... Loss: 2.8092... Val Loss: 2.8055\n",
      "Epoch: 1/1... Step: 120... Loss: 2.7139... Val Loss: 2.7205\n",
      "Epoch: 1/1... Step: 130... Loss: 2.6258... Val Loss: 2.6264\n",
      "Epoch: 1/1... Step: 140... Loss: 2.5578... Val Loss: 2.5544\n",
      "Epoch: 1/1... Step: 150... Loss: 2.4903... Val Loss: 2.4946\n"
     ]
    }
   ],
   "source": [
    "train(net, encoded_text, epochs=10, n_seq=128, n_steps=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = '4_LSTMs.net'\n",
    "\n",
    "checkpoint = {'n_hidden': net.n_hidden,\n",
    "              'n_layers': net.n_layers,\n",
    "              'state_dict': net.state_dict(),\n",
    "              'tokens': net.vocab}\n",
    "\n",
    "with open(model_name, 'wb') as f:\n",
    "    torch.save(checkpoint, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('4_LSTMs.net', 'rb') as f:\n",
    "    checkpoint = torch.load(f)\n",
    "    \n",
    "loaded = CharRNN(checkpoint['tokens'], n_hidden=checkpoint['n_hidden'], n_layers=checkpoint['n_layers'])\n",
    "loaded.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference / generating sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(net, length, first_letters, cuda=True):\n",
    "    \n",
    "    if cuda:\n",
    "        net.cuda()\n",
    "    else:\n",
    "        net.cpu()\n",
    "        \n",
    "    net.eval()\n",
    "    \n",
    "    chars = [char for char in first_letters]\n",
    "    h = net.init_hidden(1)\n",
    "    \n",
    "    for ch in first_letters:\n",
    "        char, h = net.predict(ch, h, cuda=cuda)\n",
    "\n",
    "    chars.append(char)\n",
    "    \n",
    "    for i in range(length):\n",
    "        char, h = net.predict(chars[-1], h=h, cuda=cuda)\n",
    "        chars.append(char)\n",
    "        \n",
    "    return ''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = generate(net, 1000, \"lov\", cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lovy af ariviaghd wretid\n",
      "gwot tha olu, bot ne ino: Dere cort anin'ut, crass ormiunts thot maml_. \n",
      "\"od aut o to sopon:\n",
      "\"Zonlg-ale wonver, thadeha tere has\n",
      "o that sher weste the mifeld pistwon halr\n",
      "citArcaW2n end loidd int A\n",
      "lbegaind ate wi the sheege diy haay cis oon. Afwe hcrthasr ny huinendh falppistWyapCpsi9g wosle, betilt fittetesen a harce, ifdrsydr od the ham meper o:\n",
      "\": Bot ston. \"fBe on'ay thax osart3, an Fotheocs wot Yos tom pirlklrw, bet ifd ovalu.\n",
      "\n",
      "\"'un inA bauvey tixe daed hit he.\"\n",
      "\n",
      "Iply \n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (cv-nd)",
   "language": "python",
   "name": "cv-nd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
